%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is just an example/guide for you to refer to when submitting manuscripts to Frontiers, it is not mandatory to use frontiers.cls nor frontiers.tex %
% This will only generate the Manuscript, the final article will be typeset by Frontier after acceptance. %
% %
% When submitting your files, remember to upload this *tex file, the pdf generated with it, and all the figures.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Version 2.1 Generated 2013/11/27 %%%
%%% You will need to have the following packages installed: datetime, fmtcount, etoolbox, fcprefix, which are normally inlcuded in WinEdt. %%%
%%% In http://www.ctan.org/ you can find the packages and how to install them, if necessary. %%%

\documentclass{frontiersSCNS} % for Science articles

%\setcitestyle{square}
\usepackage{url,lineno}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\linenumbers

\lstdefinestyle{display}{
  basicstyle=\ttfamily\footnotesize,
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PR start ******************************

% double spacing for editorial work
%\usepackage{setspace}
%\doublespacing

% new commands
\newcommand{\pr}[1]{[\textcolor{YellowOrange}{PR: #1}]}

% remarks:
% Images:
% Image size for figures: 180 mm width with 900 - 1200 dpi.
% 180 mm and 1200 dpi ==> 8504 pixel
% 85 mm and 1200 dpi ==> 4016
%
% maybe better: safe as pdf and then use http://tex.stackexchange.com/questions/20883/how-to-convert-pdf-to-eps
% to convert to eps (saving it from inkscape directly as eps doesn't work as
% the result is pixeled)


% PR stop ******************************
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Leave a blank line between paragraphs in stead of using \\

\copyrightyear{}
\pubyear{}

\def\journal{Neuroinformatics}%%% write here for which journal %%%
\def\DOI{}
\def\articleType{Technology Report}
\def\keyFont{\fontsize{8}{11}\helveticabold }
\def\firstAuthorLast{Rautenberg {et~al.}} %use et al only if is more than 1 author
\def\Authors{
Philipp L. Rautenberg\,$^{1,2*}$,
Ajayrama Kumaraswamy\,$^{1}$,
Alvaro Tejero-Cantero\,$^{3}$,
Christoph Doblander\,$^{4}$,
Mohammad Reza Norouzian\,$^{4}$,
Kazuki Kai\,$^{5}$,
Hans-Arno Jacobsen\,$^{4}$,
Hiroyuki Ai\,$^{5}$,
Thomas Wachtler\,$^{1}$,
and Hidetoshi Ikeno\,$^6$}
% Affiliations should be keyed to the author's name with superscript numbers and be listed as follows: Laboratory, Institute, Department, Organization, City, State abbreviation (USA, Canada, Australia), and Country (without detailed address information such as city zip codes or street names).
% If one of the authors has a change of address, list the new address below the correspondence details using a superscript symbol and use the same symbol to indicate the author in the author list.
\def\Address{$^{1}$Department of Biology II, Ludwig-Maximilians-Universität München, Germany\\
$^{2}$Max Planck Digital Library, München, Germany\\
$^{3}$MRC ANU, Department of Pharmacology, University of Oxford, United Kingdom\\
$^{4}$Department of Informatics, Technische Universität München, Germany\\
$^{5}$Department of Earth System Science, Fukuoka University, Japan\\
$^{6}$School of Human Science and Environment, University of Hyogo, Japan
}
% The Corresponding Author should be marked with an asterisk
% Provide the exact contact address (this time including street name and city zip code) and email of the corresponding author
\def\corrAuthor{Philipp L. Rautenberg}
\def\corrAddress{Max Planck Digital Library, Amalienstraße 33, 80799 München, Germany}
\def\corrEmail{rautenberg@mpdl.mpg.de}

% \color{FrontiersColor} Is the color used in the Journal name, in the title, and the names of the sections.


\begin{document}
\onecolumn
\firstpage{1}

\title[NeuronDepot - Keeping your colleagues in sync]{NeuronDepot - Keeping
your colleagues in sync by combining modern cloud storage services, the local
file system, and simple web applications}
\author[\firstAuthorLast ]{\Authors}
\address{}
\correspondance{}
\extraAuth{}% If there are more than 1 corresponding author, comment this line and uncomment the next one.
%\extraAuth{corresponding Author2 \\ Laboratory X2, Institute X2, Department X2, Organization X2, Street X2, City X2 , State XX2 (only USA, Canada and Australia), Zip Code2, X2 Country X2, email2@uni2.edu}
\topic{Recent advances and the future generation of neuroinformatics infrastructure}% If your article is part of a Research Topic, please indicate here which.

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% The sections below are for reference only.
%%%
%%% For Original Research Articles, Clinical Trial Articles, and Technology Reports the section headings should be those appropriate for your field and the research itself. It is recommended to organize your manuscript in the
%%% following sections or their equivalents for your field:
%%% Abstract, Introduction, Material and Methods, Results, and Discussion.
%%% Please note that the Material and Methods section can be placed in any of the following ways: before Results, before Discussion or after Discussion.
%%%
%%%For information about Clinical Trial Registration, please go to http://www.frontiersin.org/about/AuthorGuidelines#ClinicalTrialRegistration
%%%
%%% For Clinical Case Studies the following sections are mandatory: Abstract, Introduction, Background, Discussion, and Concluding Remarks.
%%%
%%% For all other article types there are no mandatory sections.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

\section{
Neuroscience today deals with a ``data deluge'' derived from the availability of
high-throughput sensors of brain structure and brain activity, and increased
computational resources for detailed simulations with complex output. We report
here (1) a novel approach to data sharing between collaborating scientists that
brings together file system tools and cloud technologies, (2) a service
implementing this approach, called NeuronDepot, and (3) an
example application of the service to a complex use case in the
neurosciences. The main drivers for our approach are to facilitate
collaborations with a transparent, automated data flow that shields scientists
from having to learn new tools or data structuring paradigms.  Using
NeuronDepot is simple: one-time data assignment from the originator and cloud
based syncing -- thus making experimental and modeling data available across
the collaboration with minimum overhead. Since data sharing is cloud based, our
approach opens up the possibility of using new software developments and
hardware scalabitliy which are associated with elastic cloud computing. We
provide an implementation that relies on existing synchronization services and
is usable from all devices via a reactive web interface. We are motivating our
solution by solving the practical problems of the GinJang project, a
collaboration of three universities across eight time zones with a complex
workflow encompassing data from electrophysiological recordings, imaging,
morphological reconstructions, and simulations.}

\tiny
 \keyFont{ \section{Keywords:} Morphology, Electrophysiology, Imaging, Data
 Management, Neuroinformatics, Cloud Services} %All article types: you may provide up to 8 keywords; at least 5 are mandatory.
\end{abstract}

%%%%%%%%%%%%%%
% Introduction
%%%%%%%%%%%%%%
%\twocolumn
\section{Introduction}
Science today deals with a ``data deluge'' caused by the widespread use of
high-throughput sensors in experiments, and the ever more complex simulations
afforded by increased computational power \citep{moore_cramming_1965}. Both
measured and simulated data need to be stored in raw form, preprocessed,
contextualized with metadata, organized to facilitate queries, and then
analyzed to produce scientific statements. Ideally, peer-reviewed data should
also be available for replication and re-analysis to test new hypotheses as
knowledge progresses.

In addition, the need for multi-university collaboration is particularly acute
in neuroscience being a multilevel discipline. It tackles questions spanning
disparate levels of organization such as genes, neurons, circuits, and behavior
with a variety of methods including sequencing, electrophysiology, and computer
simulations \citep{shepherd_human_1998}. Projects with such multi-university
collaborations benefit from well organized coordination of the participating
specialists \citep{cummings_coordination_2007}.

One challenging aspect of project workflows might concern immediate sharing of
highly structured and voluminous data across labs. Tasks of such a project
workflow can interdepend: a further step of the local work depends on another
operation that is remotely carried out. In this case, scientific workflows
allow to optimize and then more efficiently execute scientific processes
\citep{ludascher_scientific_2009}. For example, analysis results can motivate
further collection of experimental data, whereupon it is clearly of advantage that
they are made available once they are produced.

Proposals to alleviate the data management overhead frequently might require
scientists to change and diminish their local processing workflow in order to
be able to offer distributed access for collaborators to participate in the
project. We propose here a novel approach which integrates seamlessly the
widespread filesystem-based acquisition, analysis, and publication workflows by
leveraging proven cloud synchronization technology. Our implementation of this
approach, a service called NeuronDepot, enables researchers to continue
interacting with the scientific project data through the filesystem and at the
same time opens up the data for further processes in cloud-based web
applications. In this way NeuronDepot exploits the existing substantial
investment in development, acquisition, and training in local applications with
their mature and rich interfaces and local access to data. We illustrate the
approach with a deployment of NeuronDepot tailored to the specific needs of the
GinJang project (\url{http://projects.g-node.org/ginjang/}), a complex use case
that combines data from electrophysiological recordings, imaging, morphological
reconstructions, and simulations.

Several initiatives have established databases to make neuromorphological or
neurophysiological research data publicly available. NeuroMorpho
(\url{http://neuromorpho.org/}) is a curated inventory of digitally
reconstructed neurons. The goal of the project is to provide dense coverage of
available reconstruction data for the neuroscience community
\citep{Ascoli2007}. The neurodatabase.org project
(\url{http://neurodatabase.org}) and the Collaborative Research in
Computational Neuroscience (CRCNS) site (\url{http://crcns.org}) host
electrophysiological data that have been specifically selected by contributing
labs for the purpose of making the data available to the public.  Typically,
data in these databases are from studies that have been published and are
provided for use in further investigations after they have served their primary
purpose. Only a few projects have been designed to support data sharing in
collaborative research.

The CARMEN portal (\url{http://portal.carmen.org.uk}) allows neuroscientists to
share data and programs from neurophysiological experiments. Data analysis
functions are provided as services that can be applied to the data stored in
the system \citep{austin_carmen:_2011}. Data, metadata, and analysis workflows
are accessible via a web interface.

The German Neuroinformatics Node (G-Node) provides a platform for management
and sharing of neurophysiological data (\url{http://www.g-node.org/data}).
Users can upload, organize, and annotate data, and make them accessible to
other users or the public. Data annotation follows a flexible schema
\citep{Grewe2011} so that any metadata necessary can be entered. An API
provides fine-grained data access through common languages like Python or
Matlab, enabling data management and collaborative data sharing directly from
the scientists' local data workflow environments
\citep{Sobolev_data_2014,Sobolev_integrated_2014}.

Recently, the International Neuroinformatics Coordinating Facility (INCF)
established the INCF Dataspace (\url{http://incf.org/dataspace}), a cloud-based
file system to share all kinds of neuroscience data.

One of the first databases integrating results from various fields like
morphology, physiology, and immunohistochemistry is the Bombyx Neuron Database
for assembling and sharing experimental and analytical data \citep{Kazawa2008}.
Its integrative approach inspired also the development of NeuronDepot.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Scope of the NeuronDepot approach
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Scope of the NeuronDepot approach}

In contrast to some of the infrastructure solutions presented above,
NeuronDepot does not focus on a particular field or type of data but leaves the
specifics of each data type to the well-established working environments of the
participating members. NeuronDepot supports the scientist by providing a
service that integrates data flows with the corresponding management and data
analysis.

Beyond facilitating collaboration, the development of a database to properly
store and backup all the data of the project makes it accessible to further
projects. Putting data into structured databases facilitates its reuse and
enables replication and verification of analyses.

\subsection{The GinJang Project and its Workflow}
\label{sec:ginjang}
NeuronDepot was developed around the German-Japanese collaboration GinJang
(\url{http://projects.g-node.org/ginjang/}).
This project provides a perfect opportunity for use-case-driven development and
field-testing of the NeuronDepot infrastructure because 1) it involves three
universities with several labs across multiple time zones, 2) it deals with
different types of data from neuroanatomy and electrophysiology, and 3) it
requires quick synchronization and reliable transfer of large quantities of raw
data with complex associated metadata, including both recorded data and
simulation results.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{Figures/workflow}
\caption[Processing stages and data transitions]{
    \emph{Processing stages and data transitions of a typical workflow like the GinJang honeybee project}

    \textbf{I. Processing stages} (A) Single cell recording at a
    electrophysiological setup. Here, the electrical cell activity is measured
    at the dendrite, as well as a dye is injected into the cell. (B) Using the
    brain from experiments, image stacks are created applying confocal
    microscope technology. (C) The application SIGEN computes from confocal
    image stacks segmentations representing the underlying neuron. (D)
    Electrophysiological recordings are analyzed with specialized software.
    This stage represents an entire electrophysiological infrastructure using
    local computers at the experimental lab but also remote G-Node-services.
    For simplicity, this illustration exemplary shows the result of a spike
    detection algorithm identifies spikes of three neuronal units. (E) Further
    process stages follow building upon already processed data.

    \textbf{II. Traditional data transition} (A $\rightarrow$ B) The honeybee
    brain is physically moved from electrophysiological setup to the confocal
    microscope setup. (B $\rightarrow$ C; C $\rightarrow$ E) data units (single
    file, or set of files that represents a logical unit like all files of an
    image stack) are transferred by common tools, like USB-sticks, external
    hard drives, Dropbox, or simply as emails attachment. The same tools are
    applied for (A $\rightarrow$ D; D $\rightarrow$ E) but moreover dedicated
    web techniques for the domain of electrophysiological provided by G-Node
    are applied.
}
\label{fig:workflow}
\end{figure}
The GinJang project studies the processing of auditory signals in the honeybee.
%processes, and codes the location of food sources during dance communication.
Honeybees communicate the direction and distance to food sources with
hive-mates by waggle dance \citep{Frisch1967}. The hive-mates detect and
process airborne vibration caused by the bee's wingbeat during the waggle
dance, which consists of vibration pulses with a highly specific temporal
pattern.  Several critical interneurons for processing the airborne vibration
have been identified \citep{Ai2007, Ai2009, Ai2010, Ai2012, Ai2013}. However,
the neural processing of these vibration signals has rarely been studied: types
and roles of neurons involved, their circuitry, and their development are
largely unknown.

Members of the GinJang project also developed a program (SIGEN, see
\citet{Minemoto}) that is used to automatically extract and segment the
morphology of interneurons that are involved in vibration processing. Goal
of the GinJang project is to clarify the morphological characteristics of the
vibration-processing neurons and their morphological development according to
age and experience of the bees.

The workflow of the GinJang project is illustrated in Figures
\ref{fig:workflow} and \ref{fig:workflow_sequence}.
The experimental setup
is at Fukuoka University where electrophysiological
measurements (Fig.~\ref{fig:workflow}A), electrophysiological analyses
(Fig.~\ref{fig:workflow}D), and imaging (Fig.~\ref{fig:workflow}B) are
performed. The image stacks are used at the University of Hyogo for
neuronal segmentation (Fig.~\ref{fig:workflow}C). The resulting 3D neuronal
segmentations are then normalized by registering them to the Honeybee standard
brain (HSB; \url{http://www.neurobiologie.fu-berlin.de/BeeBrain/Project.html}), which
is done at Fukuoka University. Finally, morphological analyses, simulations,
and further analyses are done at Ludwig-Maximilians-Universität München (LMU)
(Fig.~\ref{fig:workflow}E).

\begin{figure}
\centering
\includegraphics[width=8cm]{Figures/workflow_sequence.eps}
\caption[Sequence of GinJang Workflow]{
    \emph{Sequence Diagram of the GinJang workflow (morphological
    scope)}%\pr{This figure will appear in one column within the final layout}

    The GinJang workflow starts at the Fukuoka University with two processing
    stages (indicated by solid arrows): the experimental data collection and
    the imaging processing stage. Anatomical image stacks are transferred
    (dashed arrow) to University of Hyogo where they are segmented. Segmented
    neurons are transferred to the LMU and also back to Fukuoka University
    where they are registered to the honeybee standard brain. Unregistered
    segmentation and registered segmentation are used for simulations and
    analysis at the LMU. Using analysis results, scientists in Fukuoka can
    tweak existing experiments or design new ones.
}
\label{fig:workflow_sequence}
\end{figure}


\subsubsection{Data Acquisition}

The vibration-sensitive neurons in the honeybee auditory system
are electrophysiologically and anatomically characterized at Fukuoka
University. Using sharp electrodes, voltage traces are recorded from
interneurons in response to several sensory input protocols \citep{Ai2009,
Ai2012, Kai2013}. Then the neuron is filled with a dye and
imaged at a different setup using confocal microscopy to generate anatomical
image stacks \citep{Ai2010, Ai2013}. Thus, every experiment generates
three kinds of data:

\begin{itemize}
\item Electrophysiological data (e.g., voltage and current traces)
\item Microscopy image stacks
\item Honeybee metadata (e.g. age or colony) and neuron metadata (e.g.
    phenotype)
\end{itemize}

\subsubsection{Segmentation}

Image stacks are transferred to the University of Hyogo, Japan. Here, using
automated image analysis software SIGEN \citep{Yamasaki2006, Minemoto} the 3D
structure of the neuron is extracted and stored using the SWC file format
(\url{http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html}).
At this stage two kinds of data are generated:

\begin{itemize}
    \item Segmented neuron (e.g., SWC file)
\item Parameters used for segmentation (which constitute segmentation metadata)
\end{itemize}


\subsubsection{Registration}

The morphological segmentations of the neurons are transferred back to Fukuoka
University for registration into the Honeybee Standard Brain using various
transformations. We use the honeybee standard brain to analyze the spatial
relationships among morphologically and physiologically characterized
vibration-sensitive neurons. The neuronal profiles of stained interneurons,
obtained from different preparations, are segmented as explained in the
previous section. Subsequently, the neuropilar outlines are traced
semi-automatically with Amira 4.1 \citep{Evers2005} and ITK-SNAP
(\url{http://www.itksnap.org/}).  These neuropilar label fields are used to
register the segmented neuron of each preparation into the honeybee standard
brain following the method described by \citet{Brandt2005}. Data generated at
this stage are:

\begin{itemize}
\item Registered neuron morphology
\item Parameters used for registration
\end{itemize}

\subsubsection{Analysis}

These segmentations (both registered and unregistered) are transferred to the
LMU, Germany, where 3D segmentations are used for morphometric analysis and
simulation studies. Multiple kinds of data are generated at this
stage:

\begin{itemize}
\item Model files for simulations
\item Simulation metadata, e.g., parameters of simulation, location of
    stimulation (input) and measurements (output)
\item Simulation results: visualizations and summary data
\item Morphometric analysis metadata, e.g., subregion of analysis, metrics used
\item Results of morphometric analysis: volume, surface area, number of branch points
\end{itemize}


\subsubsection{Traditional Data Transfer Methods}

The workflow of the GinJang project requires multiple data transfers between
diverse processing stages. These transfers were previously done via e-mail,
usb-sticks, external hard drives, ftp-servers, or cloud storage services (like
Dropbox, \url{http://www.dropbox.com/}). NeuronDepot replaces these traditional data transfer methods.


%%%%%%%%%%%%%%
% Requirements
%%%%%%%%%%%%%%

\section{Requirements Analysis}
We asked the members of the GinJang Project to specify the features that they
expect to have in NeuronDepot. Based on those we came up with the following set
of requirements:
\begin{enumerate}
\item Data Management
    \begin{itemize}
    \item Replacement of ``manual'' data transitions that are using memory
        devices like e-mail, USB-sticks, external hard drives, FTP-servers, or
        cloud storage services
    \item Ease of metadata assignment for various kinds of data like image
        stacks, voltage trace, and neuronal reconstructions
    \item Interrelate various kinds of data
    \item Visibility of the current state of the project through a web browser
    \item Automatic update and synchronization across project workstations
    \end{itemize}
\item Integration
    \begin{itemize}
    \item Maintenance of the well-established work environments of the participating scientists
    \item Minimization of the integration effort
    \end{itemize}
\item Data Security
    \begin{itemize}
    \item Reliability of upload and download of large data
    \item Access control
    \end{itemize}
\item Automated Backup
\item Additional Requirements
    \begin{itemize}
    \item Easy adaptation to new data-specific requirements that emerge during
        the project
    \item Support for automated data processing like metadata extraction,
        analysis, and simulation
    \item Quick overview of contents and metadata
    \item Flexible search of data
    \end{itemize}
\end{enumerate}


\begin{figure}
\centering
\includegraphics[width=\textwidth]{Figures/Metadata_DataUnits}
\caption[Metadata and data units]{
    \emph{Data units as smallest logical entity for specific data processing attached
    to the metadata of the project}

    (Left) A data unit is connected to metadata by its unique hash value id.
    Metadata are illustrated here as a graph where each points represents an
    attribute like \texttt{AGE=15}, \texttt{DATE=130525}, or
    \texttt{HONEYBEE=HB123}. The data unit could express an image stack, or a
    compartmental reconstruction of a specific neuron. (Middle) Data processing by
    a script or an applications that operates on specific input data units and that
    generates a new output data unit. For example, SIGEN generates from input data
    units expressing image stacks neural segmentations as an output data unit
    containing an SWC-file. (Right) Processing a data unit with a specific script
    or application leads to an output data unit associated with new metadata that
    is integrated into the existing metadata graph. According to our SIGEN-example,
    parameters of the segmentation algorithm are stored within the metadata graph.
}
\label{fig:metadata_dataunits}
\end{figure}
%%%%%%%%%
% Concept
%%%%%%%%%

\section{Concept}

\subsection{NeuronDepot as a Service}
\label{sec:service}
NeuronDepot is designed as a service. As opposed to a product, functionalities
of a service are set up to meet a specific set of requirements at a point in
time \citep{truex_growing_1999, bennett_service-based_2000,
bullinger_service_2003}. Therefore, the specific form of NeuronDepot changes as
the project progresses and its requirements continually evolve. Moreover,
NeuronDepot brings together other already existing service-modules, which are
reassembled and configured to meet the current requirements. While building up
NeuronDepot from its sub-services, we make sure that NeuronDepot stays
functional even when its sub-services develop with time.  Also, these
developments can be utilized in evolving NeuronDepot. By offering new
functionality in a way that is compatible with existing services, tools,
training, and working environments, the costs of data sharing in a
collaboration are brought down to a minimum while the accessibility of research
assets is future-proofed.

\subsection{Core Idea}

When handling a large amount of data, it is common for scientists to arrange
the corresponding files in a directory tree. By doing this, they often encode
metadata in the name of directories, for example, the date of recordings or
experimental parameters. NeuronDepot also uses this well established principle.
The difference is that NeuronDepot automatizes this. It employs a set of rules
to automatically create such a directory structure and arrange the data. It
uses the associated metadata (available in the database) for naming the
directories. The rules for forming this directory structure can be changed.
Thus, the same data can be organized in different structures as required by the
scientist.

\subsection{Definitions}

In this section we define terminologies which are used in explaining
NeuronDepot.

\subsubsection{Data unit}

A data unit (Fig.~\ref{fig:metadata_dataunits}, bottom left and bottom right)
is a logical grouping of one file (trivial case) or multiple files which are
generated by a single process. Examples of individual data units in the GinJang
context include: an image stack consisting of several image files, the
morphology of a neuron represented in a single SWC-file, or several plots and
tables resulting from simulations of a neuron's electrophysiological
characteristics.

\subsubsection{Context path and context trees}

Any data unit can be uniquely identified by a subset of the metadata attributes
associated with it (Fig.~\ref{fig:metadata_dataunits}). We define the context
path of a data unit as an ordered list of the specific attributes that uniquely
identify it (Fig.~\ref{fig:context_tree}). This context path can be used to
construct a path in the file system where the order of metadata attributes
corresponds to the hierarchical levels in the file system.

\begin{figure}
\centering
\includegraphics[width=85mm]{Figures/ContextTree}
\caption[Mapping data units to context trees]{
    \emph{Mapping a data unit to context trees using attached metadata}
    %\pr{This figure will appear in one column within the final layout}

    (Left) Each data unit is connected to metadata. Using this metadata allows
    the organization of data units by two aspects: The entire data of a project
    can be (1) sub-divided into divers subsets of data where (2) data units are
    arranged within a tree structure where the nodes represent metadata and the
    leafs represent the data unit. As a meaningful specification of such a
    arrangement depends on the context of data usage, we call this arrangement
    \emph{context tree}. (Right) One context tree of NeuronDepot arranges
    project data for the morphometric processing stage. The file format
    \texttt{SWC} serves as a filter argument as just SWC-files are needed for
    simulation. Metadata attributes \texttt{LABOR\_STATE}, \texttt{REGION},
    \texttt{HONEYBEE\_ID}, and \texttt{SIGEN\_PARAMETERS} serve for grouping.
    
    \emph{Example of context path ($\alpha$) pointing to a data unit containing
    a segmentation:}
    \texttt{/forager/left\_DL/HB130427/D20V05C01S01/morphology.swc} Another
    context tree of NeuronDepot arranges project data for our imaging
    processing stage. Here, the project data are reduced to image stacks.
    Metadata attributes \texttt{HONEYBEE\_ID} and \texttt{REGION} serve for
    grouping.

    \emph{Example of context path ($\beta$) pointing to the same data unit:}
    \texttt{/HB130427/left-DL/*.tiff}
}
\label{fig:context_tree}
\end{figure}

\emph{Example}: If a member of the project wants to analyze one particular
segmentation of neuron \texttt{NRN-1} of honeybee \texttt{HB123}, the following
two paths leading to the corresponding data unit would represent these
attributes:

\begin{lstlisting}[style=display]
(1) HB123/NRN-1/segmentation/
(2) segmentation/HB123/NRN-1/
\end{lstlisting}

The desired order of the attributes depends on how the data units are to be
queried for specific analyses: the path order is projected into a hierarchy and
therefore defines different grouping levels specific analyses.

\subsubsection{Projection}

A projection is the representation of a context tree within the file system. It
is comparable to materialized views of relational database management systems.


\subsection{Design Considerations}
The architecture of NeuronDepot follows these principles:

\subsubsection{Incorporation of existing open source components}

The open source ecosystem holds multiple solutions solving very specific tasks.
Some examples are SQLAlchemy\footnote{\url{http://www.sqlalchemy.org/}} (for
controlling the persistence of objects by mapping them to database structures),
numpy\footnote{\url{http://www.numpy.org/}} (solving highly optimized numerical
tasks), or matplotlib\footnote{\url{http://matplotlib.org/}} (illustrate data by
drawing graphs and figures). Moreover, the community of neuroinformatics has
added several domain-specific tools for simulations, analysis, and processing of
data from the field. We have incorporated some of these solution while
developing NeuronDepot (see \ref{sec:architecture}). NeuronDepot is also structured
so that other such solutions can be integrated to it.

\subsubsection{Utilization of established cloud services}

Cloud services have rapidly emerged as a widely accepted paradigm built around
core concepts such as on-demand computing resources, elastic scaling,
elimination of up-front investment, reduction of operational expenses, and
establishing a pay-per-use business model for information technology and
computing services. The use of cloud services helps to reduce development time
and effort.

%%%%%%%%%%%%%%%%%%%%%%%
% Using NeuronDepot
%%%%%%%%%%%%%%%%%%%%%%%

\section{How NeuronDepot Works}

\subsection{Data Arrangement: Flat on the server and Hierarchical on user work
stations}

NeuronDepot applies systematically the principle of using folder names and file
names as carrier for metadata describing the data contained in the filesystem.
For flexibility, the collection of data units is stored in a central server in
a flat structure where each data unit has a unique identifier, and the metadata
are kept separate and referenced to those identifiers. When users define a
subset of data they are interested in, along with a hierarchical arrangement
that suits their needs, NeuronDepot creates a user- and task-specific context
tree as a hierarchy of symbolic links with the data units at the leaves. By
exposing these hierarchies to a synchronization daemon, the projection is made
available to every workstation that subscribes to it.

\subsection{Data Assignment}

NeuronDepot also leverages advances in synchronization technology for the data
upload process: the user simply places new data units in a designated floating
folder (comparable to the Camera Upload folder of Dropbox, see Section
\ref{cloudBased}). This folder is
synchronized to the server. Then, the data units appear as available for
metadata assignment via a graphical user interface of NeuronDepot. Once
metadata assignment is complete, data units can be projected, as described
above, to hierarchies that are adapted to the local users' workflows. Data
units are now also accessible to cloud analytic services that directly query
the metadata database without demanding a specific projection, as these clients
are not constrained by the hierarchical data model of filesystems. NeuronDepot
thus maintains consistency all the way from the scientists' local copy of
acquired data to the cloud-based analysis platforms.

\subsection{Cloud-Based Data Flow}
\label{cloudBased}
NeuronDepot's mechanism for data transmission is based on synchronization by
GWDG Cloud Share (Fig.~\ref{fig:cloud_concept}). This cloud storage service is
used to keep all local computers that are involved in the project updated by
the server and, therefore, updated among each other. This core update process
is based on synchronization on the file system level. In order to integrate
data units into workflows, the system provides two types of base folders:
floating folders (Fig.~\ref{fig:cloud_concept}-1) and context tree folders
(Fig.~\ref{fig:cloud_concept}-3). Floating folders are provided with read/write
permissions for project members. Data within floating folders are not assigned
to the metadata structure and, therefore, are in a floating state. Floating
folders are part of the data-assignment process
(Fig.~\ref{fig:cloud_concept}-2). The second type of folder is the context tree
folder with read-only permissions for project members that synchronize
projected context trees to the local work
environment.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{Figures/cloud_concept}
\caption[NeuronDepot and its data flow]{
    \emph{NeuronDepot and its data flow}

    NeuronDepot is based on GWDG Cloud Share and simple Flask web-apps that use
    modern database management systems. GWDG Cloud Share keeps all local
    computers that are involved in the project synchronized with the server
    and, therefore, synchronized among each other. This core synchronization is
    based on the file system. In order to integrate files into workflows,
    the system provides two types of base folders: floating folders for upload
    (gray) with read/write permissions for project members and multiple data
    folders (purple, green, red) with read-only permissions for project
    members.

    The data transition workflow consists of three steps: (1) new data
    units are stored within the floating folder and synchronized to the server.
    (2) Synchronized data units within the floating folder are assigned to the
    existing project data via a web application. As NeuronDepot's web GUI uses
    responsive web design it provides optimal viewing experience -- easy
    reading and navigation with a minimum of resizing, panning, and scrolling
    -- across a wide range of devices from mobile phones to desktop computer
    monitors \citep{marcotte_responsive_2010}. The system ensures that all data
    is correctly related to each other and that all data stay consistent.
    Project members can plug scripts into this assignment process to automate
    and facilitate data processing. Moreover, the system provides diverse
    reports to brief the scientists about the current state or about recent
    changes. (3) NeuronDepot distributes data units back to project members.
    According to the underlying context tree, NeuronDepot synchronizes
    projected context tree folders by cloud storage services to the
    workstations of the scientists.
}
\label{fig:cloud_concept}
\end{figure}

The underlying data transfer workflow replaces traditional transfer methods as
described above and consists of three steps: (1) new data units are stored
within the floating folder and synchronized to the server. (2) Synchronized
data units within the floating folder are assigned to the existing project data
via a web application. As NeuronDepot's web GUI uses responsive web design it
provides optimal viewing experience -- easy reading and navigation with a
minimum of resizing, panning, and scrolling -- across a wide range of devices
from mobile phones to desktop computer monitors
\citep{marcotte_responsive_2010}. The system ensures that all data are
correctly related to each other and that all data stay consistent. Project
members can plug scripts into this assignment process to automate and
facilitate data processing. Moreover, the system provides diverse reports to
brief the scientists about the current state, or about recent changes. (3)
NeuronDepot distributes data units back to project members. According to the
underlying context tree, NeuronDepot synchronizes projected context tree
folders by cloud storage services to the workstations of the scientists.


%%%%%%%%%%%%%%%%%%%%%
% System Architecture
%%%%%%%%%%%%%%%%%%%%%
\section{System Architecture}\label{sec:architecture}

\begin{figure}
\centering
\includegraphics[width=85mm]{Figures/architecture}
\caption[Components of NeuronDepot]{
    \emph{Schematic representation of the different components of NeuronDepot}
    %\pr{This figure will appear in one column within the final layout}
    
    (A) The graphical user interface consists of two parts: a web application
    and local applications. The web application (\emph{left}) provides forms
    for assigning data, enter metadata, and annotating data with metadata. The
    upload and download processes are handled by GWDG Cloud Share incorporated by
    the filesystem projection layer (see below). Here, scientists can use
    established tools like Windows Explorer, Mac Finder, Linux Nautilus, or
    other file managers to copy files for upload in dedicated folders
    (\emph{right}) which are connected to the cloud services.
    (B) The business logic (\emph{left}) encodes the NeuronDepot logic rules
    that determine how data can be created, red, updated, and deleted.
    Moreover, when new data items are added, deleted, or modified, project-
    specific workflows can be triggered for each processing
    stage (\emph{small rectangle}). A Virtual Filesystem Projection layer
    (right) maps data items and directories to GWDG Cloud Share synchronization
    clients based on project-specific metadata and provides a consistent view
    of the file system structure.
    (C) Within a project database additional metadata are stored. This can be
    metadata which was extracted by a computational workflow or manually
    entered data. The responsibility of the storage backend is to consistently
    store data items and provide abstractions for the file system projection
    layer.
}
\label{fig:architecture}
\end{figure}

\subsection{Graphical User Interface}
The architecture underlying NeuronDepot consists of individual layers and
components (Fig.~\ref{fig:architecture}). Users can access NeuronDepot via a
web application or through cloud storage synchronization clients. NeuronDepot
distinguishes two kinds of users: registered project members which can manage
the entire project data and administrators with global permissions including
user management. NeuronDepot uses OpenIDs (\url{http://openid.net/}) for
authentication.

The graphical user interface (GUI) consists of two parts: a web application
(Fig.~\ref{fig:architecture}A, left) and local applications
(Fig.~\ref{fig:architecture}, right). The web application provides forms for
assigning data, entering metadata, annotating data with metadata, and deleting
data units and metadata. We used the micro web framework Python-Flask
(\url{http://flask.pocoo.org/}) for rapid development.

Upload and download processes are handled by GWDG Cloud Share
(\url{https://powerfolder.gwdg.de/}) incorporated by the virtual filesystem
projection layer (see below). Thus, scientists can use established tools like
Windows Explorer, Mac Finder, Linux Nautilus, or other file managers to copy
files for upload in dedicated folders (Fig.~\ref{fig:architecture}A, right).

\subsection{Business Logic and Virtual Filesystem Projection}\label{sec:projection_layer}

The business logic (Fig.~\ref{fig:architecture}B, left) encodes the NeuronDepot
logic rules that determine how data can be created, read, updated, and deleted.
We therefore propose a
Virtual Filesystem Projection layer (Fig.~\ref{fig:architecture}B, right) which
can map data items to cloud storage synchronization clients
based on project-specific metadata and provides a consistent view of the file
system structure for computational workflows.

A workflow is composed out of multiple tasks. Typically tasks extract metadata,
index data items, manipulate images or calculate statistics. Workflows are
created in Python with the help of libraries like Snakemake
\citep{Koester2012}.

Workflows are triggered explicitly by user interactions over the web
frontend or implicitly by the Virtual Filesystem Projection layer when new
files are added. The execution state of the workflow is displayed in the web
application.

The filesystem projection layer projects the data items based on metadata to
directories and files. The hierarchy of directory tree is generated by rules
using project metadata and the data items which are controlled by the
persistence layer.

\subsection{Persistence Layer}\label{sec:persistence_layer}

The persistence layer (Fig.~\ref{fig:architecture}C) consists of the following two components:

\textbf{Project Metadata} \texttt{ } Within a project database additional
metadata are stored. This can be metadata which were extracted by a computational
workflow or manually-entered data. For mapping Python objects to database
objects we use SQLAlchemy (\url{http://www.sqlalchemy.org/}) storing metadata
in an PostgreSQL (\url{http://www.postgresql.org/}).

\textbf{Storage Backend} \texttt{ } The responsibility of the storage backend
is to consistently store data items and provide abstractions for the file
system projection layer. NeuronDepot uses Camlistore
(\url{https://camlistore.org/}), which stores files like a traditional
filesystem. Moreover, it's specialized in storing higher-level objects.

\section{GinJang using NeuronDepot}

In the context of the GinJang project, NeuronDepot manages image stacks and
morphological reconstructions of neurons (see section \ref{sec:ginjang}). The
database contains all the image stacks and neuronal reconstructions currently
being analyzed as part of the project. It also contains the associated
metadata (see section \ref{sec:ginjang}). The web application presents all the
data annotated with metadata in easily readable tables so that the scientists
can keep track of it. Such a central presentation of all the data and metadata of
the project is useful during the web-based discussions of collaborators in
tracking the progress of the project.

By using NeuronDepot, the process of sharing data between the collaborators has
been made simple. The data are uploaded at the source of generation once and is
automatically made available to the workstations where it is analyzed. Any
further changes to this data, for example, if an improved neuronal
reconstruction is generated, is automatically made available to the
collaborator who is analyzing reconstructions. Thus, data sharing is achieved
with minimum manual intervention.

The data assigned to NeuronDepot are analyzed by two collaborators (at
University of Hyogo, Japan and at LMU, Germany), each requiring them in a
different hierarchical structure for their analyses. NeuronDepot automatically
provides the data in the structure the collaborators specify and thus
alleviates the need for manual organization.

\section{Discussion}

\subsection{Adaptability}
The system architecture of NeuronDepot can be conceptually divided into two
parts: the core engine, which is not specific to any processing stage, and
plain and focused modules, which are project-specific. In the GinJang project,
segmentation is a processing stage that is implemented as a dedicated plain
module storing, analyzing, and reporting segmentation data. Moreover, such a
module provides all the required features for the data and metadata produced by
this processing stage, like connecting it to other existing data in
NeuronDepot, handling upload of this data and specifying the information
necessary while presenting it to the user.

NeuronDepot can be adapted to other projects by incorporating project-specific
plain modules upon its core engine. These plain modules correspond to the
different processing stages of a project, while the core engine
remains the same.

\subsection{Distinguishing Features of NeuronDepot}

NeuronDepot provides data via file system. This opens up a plethora of tools
that are available at the local work bench, like (i) Desktop-Search using
diverse indexing methods (spotlight, locate, Copernic, Google-Desktop search)
(ii) File system explorers (for searching and sorting) (iii) Backup (iv)
Version-Control (v) Unix-world applications like \texttt{grep, find, and tree}
(since ``everything is a file'') (vi) Transmission protocols like \texttt{ftp,
ssh, and http} (vii) File Synchronization Services.

An important feature of NeuronDepot is the isolation of the upload process from
the GUI. In the conventional upload process the user indicates the file to be
uploaded and waits until the upload process is finished. This way of uploading
can be very inconvenient when uploading large files (several hundreds of MBs).
This problem is further compounded when the network connection is bad. Our
approach solves this problem by isolating the upload process from the data
assignment process. The upload process of NeuronDepot consists of two steps.
Data is copied into the GWDG Cloud Share and then assigned from there to the
database using the GUI. This upload procedure facilitates assisted assignment
of data since the data are available beforehand. Certain analysis scripts can be
started on the data in the virtual file system and its results can be later
used during the assignment of the data via the web-GUI.

At the end user, a subset of the data in the database is presented in a tree
structure. Such a representation of a desired subset of the data in a hierarchical
structure provides a partitioning/grouping of the data which becomes very handy
if the user intends to perform analysis or comparison on a specific subset of
the data.

In NeuronDepot, a specific subset of data is encapsulated into an entity via
the concept of context trees. Such an encapsulation facilitates management
operations such as referencing, tagging, and sharing, in which treatment of the
subset of the data as an entity is essential. This is very much like a book
encapsulating a set of concepts/facts and making them a single entity.

\subsection{Comparison with other systems}

Other file-based solutions for collaborative data sharing provide access
through a web browser, like the web platforms of CARMEN
(\url{http://portal.carmen.org.uk}) and G-Node
(\url{http://www.g-node.org/data}). There, manual download is required to
access new data when a dataset has been updated, whereas in NeuronDepot
the new data are automatically provided locally.

CARMEN enables access to analysis services on its platform
\citep{austin_carmen:_2011}. G-Node provides access to data in a common
representation through an API \citep{Sobolev_integrated_2014} with client tools for
integration with the scientist's analysis scripts \citep{Sobolev_data_2014}.
NeuronDepot complements these approaches by presenting the data in the usual
file system way. This is particularly useful for collaborations between
specific labs where all partners know how to access the data.

Unlike with other existing solutions, using NeuronDepot does not require
learning a new GUI or any other infrastructure specific usage features since at
the user end, the data are provided as directory trees. Having this feature,
project members could keep their established working environments. In other
words: NeuronDepot adapts for existing workflows whereas other systems require
the scientist to adapt its workflow to the new system.

\subsection{Further Directions, Limitations, and Open Questions}

A package/extension for an existing web-framework like Flask or Django can be
developed by reorganizing the system components of NeuronDepot. Several
existing solutions of the Open Source Ecosystem were used in the development of
NeuronDepot and this is a way of contributing back to it. Moreover, it
serves as a good building block for the development of new data software.

As explained in section \ref{sec:service}, NeuronDepot is a service which
develops as the associated project progresses. In the context of the GinJang
project, extensions to NeuronDepot are being developed which automate
morphological analysis and simulations using the neuronal reconstructions.

At the moment, the context trees used to provide the user with data are
hard-coded. The user has to communicate with the developers to have different
data structures provided. This process can be slow and can prove to be a
hindrance to the scientist's work. A service can be incorporated which enables
the user to specify what data structure is needed. This would reduce the user's
dependence on the developers and also allow the user to quickly adjust the data
that are required from NeuronDepot.

\section{Conclusion}
With this software architecture, we contribute an approach to scientific data
workflow and a tool to the ecosystem of neuroscientific software. NeuronDepot's
principal merit is that it integrates smoothly with established tools and
resolves the transition from local to cloud-based processing. In doing so,
it enables researchers to leverage the advantages of cloud services while not
requiring them to relinquish control of their data or analysis.

\section*{Disclosure/Conflict-of-Interest Statement}
%Frontiers follows the recommendations by the International Committee of Medical Journal Editors (http://www.icmje.org/ethical_4conflicts.html) which require that all financial, commercial or other relationships that might be perceived by the academic community as representing a potential conflict of interest must be disclosed. If no such relationship exists, authors will be asked to declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. When disclosing the potential conflict of interest, the authors need to address the following points:
%# Did you or your institution at any time receive payment or services from a third party for any aspect of the submitted work?
%# Please declare financial relationships with entities that could be perceived to influence, or that give the appearance of potentially influencing, what you wrote in the submitted work.
%# Please declare patents and copyrights, whether pending, issued, licensed and/or receiving royalties relevant to the work.
%# Please state other relationships or activities that readers could perceive to have influenced, or that give the appearance of potentially influencing, what you wrote in the submitted work.

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

% \section*{Author Contributions}
%When determining authorship the following criteria should be observed:
%# Substantial contributions to the conception or design of the work; or the acquisition, analysis, or interpretation of data for the work; AND
%# Drafting the work or revising it critically for important intellectual content; AND
%# Final approval of the version to be published ; AND
%# Agreement to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigated and resolved.
%Contributors who meet fewer than all 4 of the above criteria for authorship should not be listed as authors, but they should be acknowledged. (http://www.icmje.org/roles_a.html)

% The statement about the authors and contributors can be up to several sentences long, describing the tasks of individual authors referred to by their initials and should be included at the end of the manuscript before the References section.

\section*{Acknowledgement}
We thank Andrey Sobolev, Adrian Stoewer, and Christian Kellner for discussions
and contributions to a previous version.
Supported by the Japan Science and Technology Agency (JST) and the Federal
Ministry of Education and Research (BMBF, grant 01GQ1116) and a Hyogo Overseas
Research Network (HORN) Scholarship.

%\paragraph{Funding\textcolon}

\bibliographystyle{frontiersinSCNS&ENG} % for Science and Engineering articles
%\bibliographystyle{frontiersinMED&FPHY} % for Medicine and Physics articles
\bibliography{neuron_depot}

% \section*{Figures}

%%% Use this if adding the figures directly in the mansucript, if so, please remember to also upload the files when submitting your article
%%% There is no need for adding the file termination, as long as you indicate where the file is saved. In the examples below the files (logo1.jpg and logo2.eps) are in the Frontiers LaTeX folder
%%% If using *.tif files convert them to .jpg or .png

%\begin{figure}
%\begin{center}
%\includegraphics[width=3.5cm]{logo1}% This is a *.jpg file
%\end{center}
% \textbf{\refstepcounter{figure}\label{fig:01} Figure \arabic{figure}.}{ Enter the caption for your figure here. Repeat as necessary for each of your figures }
%\end{figure}

%\begin{figure}
%\begin{center}
%\includegraphics[width=3.5cm]{logo2}% This is an *.eps file
%\end{center}
% \textbf{\refstepcounter{figure}\label{fig:02} Figure \arabic{figure}.}{ Enter the caption for your figure here. Repeat as necessary for each of your figures }
%\end{figure}

%%% Frontiers will add the figures at the end of the provisional pdf automatically %%%

%%% The use of LaTeX coding to draw Diagrams/Figures/Structures should be avoided. They should be external callouts including graphics.

\end{document}
